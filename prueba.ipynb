{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://linkedin.com/uas/login\")\n",
    "time.sleep(5)\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Links are being collected now.\n",
      "Found 0 links for job offers\n",
      "Visiting the links and collecting information just started.\n"
     ]
    }
   ],
   "source": [
    "# Creating a webdriver instance\n",
    "driver = webdriver.Chrome()\n",
    "# This instance will be used to log into LinkedIn\n",
    " \n",
    "# Opening linkedIn's login page\n",
    "driver.get(\"https://linkedin.com/uas/login\")\n",
    " \n",
    "# waiting for the page to load\n",
    "time.sleep(2)\n",
    " \n",
    "# entering username\n",
    "username = driver.find_element(By.ID, \"username\")\n",
    " \n",
    "# In case of an error, try changing the element\n",
    "# tag used here.\n",
    " \n",
    "# Enter Your Email Address\n",
    "username.send_keys(\"julietaciare77@gmail.com\") \n",
    " \n",
    "# entering password\n",
    "pword = driver.find_element(By.ID, \"password\")\n",
    "# In case of an error, try changing the element\n",
    "# tag used here.\n",
    " \n",
    "# Enter Your Password\n",
    "pword.send_keys(\"Many4409\")       \n",
    " \n",
    "# Clicking on the log in button\n",
    "# Format (syntax) of writing XPath -->\n",
    "# //tagname[@attribute='value']\n",
    "driver.find_element(By.XPATH, \"//button[@type='submit']\").click()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>company_location</th>\n",
       "      <th>work_method</th>\n",
       "      <th>post_date</th>\n",
       "      <th>work_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [job_title, company_name, company_location, work_method, post_date, work_time]\n",
       "Index: []"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_url = f\"https://www.linkedin.com/jobs/search/?currentJobId=3672824246&geoId=100446943&keywords=junior%20data%20analyst&location=Argentina&refresh=true\"\n",
    "driver.get(jobs_url)\n",
    "time.sleep(3)\n",
    "# Go to search \n",
    "#buscar = driver.find_element(By.CLASS_NAME,\"scaffold-layout__list-container\")\n",
    "\n",
    "#elemento_texto = buscar.text\n",
    "\n",
    "# Get all links for these offers\n",
    "links = []\n",
    "# Navigate 13 pages\n",
    "print('Links are being collected now.')\n",
    "try: \n",
    "    for page in range(2,14):\n",
    "        time.sleep(2)\n",
    "        jobs_block = driver.find_element_by_class_name('jobs-search-results__list')\n",
    "        jobs_list= jobs_block.find_elements(By.CSS_SELECTOR, '.jobs-search-results__list-item')\n",
    "    \n",
    "        for job in jobs_list:\n",
    "            all_links = job.find_elements_by_tag_name('a')\n",
    "            for a in all_links:\n",
    "                if str(a.get_attribute('href')).startswith(\"https://www.linkedin.com/jobs/view\") and a.get_attribute('href') not in links: \n",
    "                    links.append(a.get_attribute('href'))\n",
    "                else:\n",
    "                    pass\n",
    "            # scroll down for each job element\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView();\", job)\n",
    "        \n",
    "        print(f'Collecting the links in the page: {page-1}')\n",
    "        # go to next page:\n",
    "        driver.find_element_by_xpath(f\"//button[@aria-label='Page {page}']\").click()\n",
    "        time.sleep(3)\n",
    "except:\n",
    "    pass\n",
    "print('Found ' + str(len(links)) + ' links for job offers')\n",
    "\n",
    "# Create empty lists to store information\n",
    "job_titles = []\n",
    "company_names = []\n",
    "company_locations = []\n",
    "work_methods = []\n",
    "post_dates = []\n",
    "work_times = [] \n",
    "job_desc = []\n",
    "\n",
    "i = 0\n",
    "j = 1\n",
    "# Visit each link one by one to scrape the information\n",
    "print('Visiting the links and collecting information just started.')\n",
    "for i in range(len(links)):\n",
    "    try:\n",
    "        driver.get(links[i])\n",
    "        i=i+1\n",
    "        time.sleep(2)\n",
    "        # Click See more.\n",
    "        driver.find_element_by_class_name(\"artdeco-card__actions\").click()\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Find the general information of the job offers\n",
    "    contents = driver.find_elements_by_class_name('p5')\n",
    "    for content in contents:\n",
    "        try:\n",
    "            job_titles.append(content.find_element_by_tag_name(\"h1\").text)\n",
    "            company_names.append(content.find_element_by_class_name(\"jobs-unified-top-card__company-name\").text)\n",
    "            company_locations.append(content.find_element_by_class_name(\"jobs-unified-top-card__bullet\").text)\n",
    "            work_methods.append(content.find_element_by_class_name(\"jobs-unified-top-card__workplace-type\").text)\n",
    "            post_dates.append(content.find_element_by_class_name(\"jobs-unified-top-card__posted-date\").text)\n",
    "            work_times.append(content.find_element_by_class_name(\"jobs-unified-top-card__job-insight\").text)\n",
    "            print(f'Scraping the Job Offer {j} DONE.')\n",
    "            j+= 1\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Scraping the job description\n",
    "    job_description = driver.find_elements_by_class_name('jobs-description__content')\n",
    "    for description in job_description:\n",
    "        job_text = description.find_element_by_class_name(\"jobs-box__html-content\").text\n",
    "        job_desc.append(job_text)\n",
    "        print(f'Scraping the Job Offer {j}')\n",
    "        time.sleep(2)  \n",
    "            \n",
    "# Creating the dataframe \n",
    "df = pd.DataFrame(list(zip(job_titles,company_names,\n",
    "                    company_locations,work_methods,\n",
    "                    post_dates,work_times)),\n",
    "                    columns =['job_title', 'company_name',\n",
    "                           'company_location','work_method',\n",
    "                           'post_date','work_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Analytics Engineer\\nCookUnity\\nBuenos Aires, Provincia de Buenos Aires, Argentina\\n1 contacto trabaja aquí\\nPromocionado\\nData Analytics and Insights: Analytics and Modeling Analyst\\nAccenture Argentina\\nBuenos Aires, Provincia de Buenos Aires, Argentina (Presencial)\\n27 antiguos alumnos de la universidad trabajan aquí\\nPromocionado\\nJr. Collections Analyst\\nMedia.Monks\\nBuenos Aires, Provincia de Buenos Aires, Argentina (Híbrido)\\nTu perfil se ajusta a este empleo\\nPromocionado\\nJr/SSr Data Analyst (Olivos/Barracas)\\nPwC Argentina\\nProvincia de Buenos Aires, Argentina (Híbrido)\\n5 antiguos empleados de la empresa trabajan aquí\\nPromocionado\\nAnalista de datos\\nCOTO\\nBuenos Aires y alrededores (Híbrido)\\n2 contactos trabajan aquí\\nSolicitado hace 16 horas\\nAnalista de Inteligencia comercial\\nMolino Cañuelas SACIFIA\\nCarlos Spegazzini, Provincia de Buenos Aires, Argentina (Presencial)\\nEn busca de personal\\nPromocionado\\nSolicitud sencilla\\nAssociate Data Scientist\\nBBVA en Argentina\\nBuenos Aires y alrededores (Híbrido)\\n8 contactos trabajan aquí\\nPromocionado\\nSolicitud sencilla'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elemento_texto "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(BY.CLASS_NAME,scaffold-layout__list-container)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
